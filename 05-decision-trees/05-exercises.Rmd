---
title: "05-exercises"
author: "Ai Sasho"
date: "2016-05-07"
output: html_document
---

## Reading:
- **APM** Chapter 8.1-8.5 "Regression Trees and Rule-Based Models" (25 pages)
- **APM** Chapter 14.1-14.5 "Classification Trees and Rule-Based"
- Read about trainControl

```{r, echo=FALSE, results='hide', warning=FALSE }
packs <-  c('ggplot2', 'magrittr', 'dplyr', 'caret', 'AppliedPredictiveModeling')

for( nm in packs ) { 
  # message(nm)
  if( ! nm  %in% installed.packages()[,1]  ) install.packages(nm)
  library(nm, character.only = TRUE)
}

.. = NULL  # For Aesthetics

```


## Exercise 1: GermanCredit

Revisit the GermanCredit data. Use `caret` to build models of `Class` using the following techniques:

- glm
- rpart
- knn
- party::ctree
- randomForest
- A method of your choice from the Caret Model List (you will need to install any dependencies)

Save the caret objects with the names provided.

```{r}
library(caret)
data(GermanCredit)

control <-  trainControl( method="boot", number=5, classProb=TRUE, savePrediction=TRUE )

fit.glm <- train(Class ~ ., data=GermanCredit, method="glm", family="binomial", trControl=control, tuneLength=20)

fit.knn <- train(Class ~ ., data=GermanCredit, method="knn", trControl=control, tuneLength=20)

fit.rpart <- train(Class ~ ., data=GermanCredit, method="rpart", trControl=control, tuneLength=20)

fit.myown <- train(Class ~ ., data=GermanCredit, method="gpls", trControl=control)

```


- Compare the models using `caret::confusionMatrix`
- Comparing the models Using the `pROC` packages
  - create ROC curves for the models 
  
Show your work! 

```{r}

# Confusion matrix
table(fit.glm$pred$pred, fit.glm$pred$obs) %>% confusionMatrix()
table(fit.knn$pred$pred, fit.knn$pred$obs) %>% confusionMatrix()
table(fit.rpart$pred$pred, fit.rpart$pred$obs) %>% confusionMatrix()
table(fit.myown$pred$pred, fit.myown$pred$obs) %>% confusionMatrix()

# ROC
library(pROC)
roc.fit.glm <- roc(fit.glm$pred$obs, fit.glm$pred$Bad, auc=TRUE )
roc.fit.glm %>% plot( print.auc=TRUE, grid=TRUE)

roc.fit.knn <- roc(fit.knn$pred$obs, fit.knn$pred$Bad, auc=TRUE )
roc.fit.knn %>% plot( print.auc=TRUE, grid=TRUE)

roc.fit.rpart <- roc(fit.rpart$pred$obs, fit.rpart$pred$Bad, auc=TRUE )
roc.fit.rpart %>% plot( print.auc=TRUE, grid=TRUE)

roc.fit.myown <- roc(fit.myown$pred$obs, fit.myown$pred$Bad, auc=TRUE )
roc.fit.myown %>% plot( print.auc=TRUE, grid=TRUE)
```


Q: Which models would you select based on these tools?

Answer: I would select GLM amongst the models abole. The GLM model has a higher accuracy of 0.74 and the kappa value of 0.35, and the ROC curve shows that the higher sensitivity and the specificity than other models.

Q: If you assume that a `Class=="bad""` is 10 more costly than `Class=="good"`, determine your threshold for the model of your choice.  Show your work.

Answer: Analyzing the output from the model below, I would determine the threshold of cp = 0.005698006, as that cp value gives the highest accuracy of 0.6040423. I am not exactly sure why the overall acurracy decreased, when given a cost matrix in the CART model. (Please note that the highest cp and accuracy are different in each run, so the exact values may differ).

```{r}
cost.matrix <- matrix(c(0, 1, 10, 0), ncol=2)
fit.rpart.cost <- train(Class ~ ., data=GermanCredit, method="rpart", trControl=control, tuneLength=40, parms=list(loss=cost.matrix) )
fit.rpart.cost 
```


